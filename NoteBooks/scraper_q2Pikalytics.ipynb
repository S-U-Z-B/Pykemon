{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import bs4 as bs\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from IPython import embed\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "website = 'https://www.pikalytics.com/pokedex/ss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following two functions is to either download the html of a website page, or to open the website using selenium. In the case of websites which require dynamically generated content (without the url change. Javascript for example), selenium is required. For pikalytics, there are a lot of javascript interactions (one single url with a lot of different information depending on where we click), which means we need to open the page with selenium, which is a headless browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The directory for \"geckodriver\" must be specified to the location of the file within the submission folder to allow the scraper to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(page, addition=''):\n",
    "    return bs.BeautifulSoup(urlopen(Request(page + addition,\n",
    "            headers={'User-Agent': 'Opera/9.80 (X11; Linux i686; Ub'\\\n",
    "                     'untu/14.10) Presto/2.12.388 Version/12.16'})).read(), 'lxml')\n",
    "\n",
    "def fetch_sel(page, headless = True):\n",
    "\toptions = webdriver.FirefoxOptions()\n",
    "\tif headless:\n",
    "\t\toptions.add_argument('-headless')\n",
    "\tdirect = os.path.dirname(__file__)\n",
    "\texe_path = os.path.join(direct, 'geckodriver')\n",
    "\texe_path = '/Users/ajkea/Documents/geckodriver'\n",
    "\tdriver = webdriver.Firefox(executable_path=exe_path,options=options)\n",
    "\tdriver.get(page)\n",
    "\t\n",
    "\thtml = driver.page_source\n",
    "\treturn bs.BeautifulSoup(html,'lxml'), driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is the main scraping function. Here are the steps to get the data.\n",
    "\n",
    "1. Create empty dataframes, and list of formats (used later)\n",
    "2. The main scraping loop.\n",
    "    1. Loop through every section (league). Here, we can't change the url to get to the desited page. We need to select the correct option from the dropdown menu.\n",
    "    2. Once the section has been selected, we loop through the top 20 pokemons, clicking on each of them.\n",
    "    3. Once we have clicked on a pokemon, the stats/items/abilities page appear. This is where we gather the information. This is done by finding the id of *moves_wrapper* for example and gathering the move/% pair.\n",
    "    4. The information is then added to the full pandas dataframe.\n",
    "3. Repeart 3.1 for the following sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pikalytics_stats(website, top_n=20):\n",
    "\t''' Gets all stats, moves, items for top 20 pokemons'''\n",
    "\tresult_page, driver = fetch_sel(f'{website}')\n",
    "\ttime.sleep(5)\n",
    "\tdropdown = driver.find_element_by_id(\"format_dd\")\n",
    "\toptions = dropdown.find_elements_by_tag_name('option')\n",
    "\tscrape_names = ['Showdown VGC 2021 (0+)','OverUsed (0+)','Ubers','UnderUsed','RarelyUsed','NeverUsed',\n",
    "\t\t\t\t\t'PU','VGC 2019 Ultra Series','VGC 2018','VGC 2017','Gen 7 OverUsed']\n",
    "\t\n",
    "\tdf = pd.DataFrame(columns = ['section','poke_name','perc_use','url','stats','moves','items'])\n",
    "\n",
    "\tfor section in [x.text for x in options]:\n",
    "\t\tif section in scrape_names:\n",
    "\t\t\tprint(section)\n",
    "\t\t\tdropdown = driver.find_element_by_id(\"format_dd\")\n",
    "\t\t\tselector = Select(dropdown)\n",
    "\t\t\tselector.select_by_visible_text(section)\n",
    "\t\t\ttime.sleep(3)\n",
    "\t\t\ta = driver.find_element_by_xpath('//*[@id=\"min_list\"]')\n",
    "\t\t\tlen_a = len(a.find_elements_by_tag_name('a'))\n",
    "\t\t\tfor i in range(1,min(top_n,len_a)+1):\n",
    "\t\t\t\tpoke_box = driver.find_element_by_xpath(f'//*[@id=\"min_list\"]/a[{i}]')\n",
    "\t\t\t\turl_ = poke_box.get_attribute('href')\n",
    "\t\t\t\tpoke_name = poke_box.get_attribute('data-name')\n",
    "\t\t\t\tperc_val = float(driver.find_element_by_xpath(f'//*[@id=\"min_list\"]/a[{i}]/span').text.strip().replace('%',''))/100\n",
    "\t\t\t\t\n",
    "\t\t\t\tbs4_text = fetch(url_)\n",
    "\t\t\t\tstats_ = bs4_text.find('div',{'id':'bstats_wrapper'})\n",
    "\t\t\t\tstats_names = stats_.find_all('div',{'style':'display:inline-block;width:30px;text-align: left;'})\n",
    "\t\t\t\tstats_vals = stats_.find_all('div',{'style':'display:inline-block;vertical-align: middle;margin-left: 20px;'})\n",
    "\t\t\t\tstats = ''\n",
    "\t\t\t\tfor idx, v in enumerate(stats_names):\n",
    "\t\t\t\t\tstat = f'{stats_names[idx].text}:{stats_vals[idx].text};'\n",
    "\t\t\t\t\tstats += stat\n",
    "\n",
    "\t\t\t\tmoves_ = bs4_text.find('div',{'id':'moves_wrapper'})\n",
    "\t\t\t\tmove_list = ''\n",
    "\t\t\t\tfor move in moves_.find_all('div',{'class':'pokedex-move-entry-new'}):\n",
    "\t\t\t\t\tmove_name = move.find('div',{'style':'margin-left:10px;display:inline-block;'}).text\n",
    "\t\t\t\t\tmove_perc = move.find('div',{'style':'display:inline-block;float:right;'}).text\n",
    "\t\t\t\t\tmove_list += f\"{move_name}:{move_perc};\"\n",
    "\n",
    "\t\t\t\titems_ = bs4_text.find('div',{'id':'items_wrapper'})\n",
    "\t\t\t\titems_list = ''\n",
    "\t\t\t\tfor item in items_.find_all('div',{'class':'pokedex-move-entry-new'}):\n",
    "\t\t\t\t\titem_name = item.find('div',{'style':'display:inline-block;'}).text\n",
    "\t\t\t\t\titem_perc = item.find('div',{'style':'display:inline-block;float:right;'}).text\n",
    "\t\t\t\t\titems_list += f\"{item_name}:{item_perc};\"\n",
    "\n",
    "\t\t\t\tdf = df.append({'section':section,'poke_name':poke_name,'perc_use':perc_val,'url':url_,'stats':stats,\n",
    "\t\t\t\t\t\t\t\t\t'moves':move_list,'items':items_list}, ignore_index=True)\n",
    "\n",
    "\n",
    "\tdf.to_csv('pikalytics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pikalytics_stats(website)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
